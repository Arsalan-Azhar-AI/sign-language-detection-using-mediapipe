{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZenlfFB_Sejp",
        "outputId": "3f69195c-9ada-4f4a-8afc-e3b5259c34e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y15vDf47GiA"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK4naVyW7Q75",
        "outputId": "c40e0933-9ee7-47e3-ee37-837e8405de5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jahanzebnaeem/wlpsl\n",
            "License(s): other\n",
            "Downloading wlpsl.zip to /content\n",
            "100% 350M/350M [00:18<00:00, 19.9MB/s]\n",
            "100% 350M/350M [00:18<00:00, 19.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jahanzebnaeem/wlpsl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hznUedY7YHV",
        "outputId": "3f4e202f-7546-4a37-897c-78714ce4a46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set is extracted\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "data='/content/wlpsl.zip'\n",
        "with ZipFile(data,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Data set is extracted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV34BZ1K7dm9",
        "outputId": "3ed41507-f1fc-4c88-ec8b-03a8f3513b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.20)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rylkq3a7nRs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G9EGXQC7rfs"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic # Holistic model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
        "mp_face_mesh = mp.solutions.face_mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUOAs2Ks7uUk"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
        "    return image, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_WI8A0m7xds"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             )\n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    # Draw right hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wWQKifp70zU"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    return np.concatenate([pose, face, lh, rh])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COUCPcQzLIWy",
        "outputId": "02f163f7-141f-4f9a-bcb4-ef7a55e123bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected items copied to /content/WLPSL/Videos1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Source folder path\n",
        "source_folder = \"/content/WLPSL/Videos\"\n",
        "\n",
        "# Destination folder path\n",
        "destination_folder = \"/content/WLPSL/Videos1\"\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# List of subfolders or files to include\n",
        "include = [\"alert\", \"careful\", \"cheap\"]\n",
        "\n",
        "# Iterate through the source folder\n",
        "for item in os.listdir(source_folder):\n",
        "    source_path = os.path.join(source_folder, item)\n",
        "    destination_path = os.path.join(destination_folder, item)\n",
        "\n",
        "    # Check if the item is in the include list\n",
        "    if item in include:\n",
        "        # Copy folder or file\n",
        "        if os.path.isdir(source_path):\n",
        "            shutil.copytree(source_path, destination_path)\n",
        "        else:\n",
        "            shutil.copy2(source_path, destination_path)\n",
        "\n",
        "print(f\"Selected items copied to {destination_folder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NREuLDzBoQI0"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/WLPSL/Videos1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q74ry1d75eP",
        "outputId": "0b116fb8-a0b5-4c6a-ab5c-a082c25171a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frames extracted for 4.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 6.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 1.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 8.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 5.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 7.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 3.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 2.mp4 in gesture folder 'ready'\n",
            "Frames extracted for 4.mp4 in gesture folder 'good'\n",
            "Frames extracted for 6.mp4 in gesture folder 'good'\n",
            "Frames extracted for 1.mp4 in gesture folder 'good'\n",
            "Frames extracted for 8.mp4 in gesture folder 'good'\n",
            "Frames extracted for 5.mp4 in gesture folder 'good'\n",
            "Frames extracted for 7.mp4 in gesture folder 'good'\n",
            "Frames extracted for 3.mp4 in gesture folder 'good'\n",
            "Frames extracted for 2.mp4 in gesture folder 'good'\n",
            "Frames extracted for 4.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 6.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 1.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 8.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 5.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 7.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 3.mp4 in gesture folder 'dumb'\n",
            "Frames extracted for 2.mp4 in gesture folder 'dumb'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing videos\n",
        "video_folder = '/content/WLPSL/Videos1'  # Update with the path to your videos\n",
        "# Directory to save extracted frames\n",
        "output_folder = 'MP_Data'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "# Number of frames to extract per video\n",
        "frames_per_sequence = 30\n",
        "\n",
        "# Function to extract exactly 30 frames uniformly\n",
        "def extract_frames_from_video(video_path, output_folder, gesture_folder, video_index):\n",
        "  with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate frame indices to sample\n",
        "    frame_indices = np.linspace(0, total_frames - 1, frames_per_sequence, dtype=int)\n",
        "\n",
        "    extracted_count = 0\n",
        "    output_subfolder = os.path.join(output_folder, gesture_folder, str(video_index))\n",
        "    os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "    frame_count = 0\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        image, results = mediapipe_detection(frame, holistic)\n",
        "        draw_styled_landmarks(image, results)\n",
        "\n",
        "\n",
        "        if frame_count in frame_indices:\n",
        "            # Preprocess frame (example: using Mediapipe or other processing)\n",
        "            keypoints = extract_keypoints(results)  # Replace with your desired preprocessing logic\n",
        "            frame_filename = os.path.join(output_subfolder, f\"{extracted_count + 1}\")\n",
        "            np.save(frame_filename, keypoints)\n",
        "            extracted_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "# Loop through all videos in the folder\n",
        "for gesture_folder in os.listdir(video_folder):\n",
        "    gesture_path = os.path.join(video_folder, gesture_folder)\n",
        "\n",
        "    if os.path.isdir(gesture_path):  # Check if it's a folder for gestures\n",
        "        video_index = 1  # Start numbering videos from 1\n",
        "        for filename in os.listdir(gesture_path):\n",
        "            if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):  # Adjust for your video file type\n",
        "                video_path = os.path.join(gesture_path, filename)\n",
        "                extract_frames_from_video(video_path, output_folder, gesture_folder, video_index)\n",
        "                print(f\"Frames extracted for {filename} in gesture folder '{gesture_folder}'\")\n",
        "                video_index += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fc5bIlR8L7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "actions=[action_name for action_name in os.listdir(\"/content/MP_Data\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em9FvlnWFaB-",
        "outputId": "00585a49-afed-4388-b36b-4d5c48855c01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELgRELOS5gx5"
      },
      "outputs": [],
      "source": [
        "actions=np.array(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Bapsu084AZ",
        "outputId": "4b83a906-7c2b-49da-bde9-ae4b3850ae20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ready', 'good', 'dumb'], dtype='<U5')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR3T4KAa8-6j"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vdul1KN9OBt"
      },
      "outputs": [],
      "source": [
        "label_map = {label:num for num, label in enumerate(actions)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9puU_ygaFiuM",
        "outputId": "6675ad8b-3efe-444a-a4ed-59397afeb573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NQW9yLu9Rg-",
        "outputId": "7aa22357-99eb-4bc1-a831-53b9001c4d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ready': 0, 'good': 1, 'dumb': 2}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4b2Rm-V9U8g"
      },
      "outputs": [],
      "source": [
        "sequence_length=30\n",
        "DATA_PATH=\"/content/MP_Data\"\n",
        "sequences, labels = [], []\n",
        "for action in actions:\n",
        "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
        "        window = []\n",
        "        for frame_num in range(sequence_length):\n",
        "          frame_num=frame_num+1\n",
        "          res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        labels.append(label_map[action])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL1T50fs9f7_",
        "outputId": "55223de3-0217-4be0-b089-1e3facaf98c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 30, 1662)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(sequences).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM7GetMU9jn3",
        "outputId": "5902194e-09f5-479c-9bf5-56d6e2740851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24,)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(labels).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRU0npkN9oZ3"
      },
      "outputs": [],
      "source": [
        "X = np.array(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5fLnaod9rBu"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(labels).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "k0NRMQJe9t4h",
        "outputId": "69b63781-4a00-4346-81ef-4c48a0e9ecaa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4882b9ec44ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHQV3F_w9xmt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uskE2z890V0"
      },
      "outputs": [],
      "source": [
        "log_dir = os.path.join('Logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anAsWutT97Vg"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
        "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYrZZDZW-DHE"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PjnRD6og-Fv4",
        "outputId": "0903936c-17a1-4d9e-feb9-3be95fd92c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - categorical_accuracy: 0.3182 - loss: 1.0985\n",
            "Epoch 2/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.3182 - loss: 1.1013\n",
            "Epoch 3/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.4091 - loss: 1.0903\n",
            "Epoch 4/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.2727 - loss: 5.6408\n",
            "Epoch 5/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3182 - loss: 1.1200\n",
            "Epoch 6/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3636 - loss: 1.1196\n",
            "Epoch 7/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3636 - loss: 1.0666\n",
            "Epoch 8/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.4091 - loss: 1.9218\n",
            "Epoch 9/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3182 - loss: 1.6827\n",
            "Epoch 10/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.2727 - loss: 3.6936\n",
            "Epoch 11/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.2273 - loss: 11.5005\n",
            "Epoch 12/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.3636 - loss: 1.9090\n",
            "Epoch 13/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3182 - loss: 9.1624\n",
            "Epoch 14/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - categorical_accuracy: 0.4091 - loss: 4.3428\n",
            "Epoch 15/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2273 - loss: 4.7477\n",
            "Epoch 16/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - categorical_accuracy: 0.3636 - loss: 2.6951\n",
            "Epoch 17/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.1818 - loss: 2.6642\n",
            "Epoch 18/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - categorical_accuracy: 0.4091 - loss: 3.9097\n",
            "Epoch 19/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2727 - loss: 10.9546\n",
            "Epoch 20/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2727 - loss: 2.7625\n",
            "Epoch 21/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.2727 - loss: 2.4038\n",
            "Epoch 22/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.3636 - loss: 4.3645\n",
            "Epoch 23/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3182 - loss: 2.7140\n",
            "Epoch 24/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.1818 - loss: 4.4055\n",
            "Epoch 25/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3636 - loss: 5.2766\n",
            "Epoch 26/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.1818 - loss: 5.3249\n",
            "Epoch 27/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - categorical_accuracy: 0.3182 - loss: 3.6417\n",
            "Epoch 28/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.4091 - loss: 1.9059\n",
            "Epoch 29/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.4545 - loss: 2.6877\n",
            "Epoch 30/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3636 - loss: 2.1201\n",
            "Epoch 31/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.3636 - loss: 1.8103\n",
            "Epoch 32/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.3636 - loss: 3.0376\n",
            "Epoch 33/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.4545 - loss: 3.0056\n",
            "Epoch 34/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - categorical_accuracy: 0.4545 - loss: 1.7938\n",
            "Epoch 35/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 3.9404\n",
            "Epoch 36/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.3182 - loss: 3.1215\n",
            "Epoch 37/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - categorical_accuracy: 0.4091 - loss: 3.3841\n",
            "Epoch 38/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.2727 - loss: 4.4346\n",
            "Epoch 39/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.3636 - loss: 5.7280\n",
            "Epoch 40/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.2727 - loss: 6.6477\n",
            "Epoch 41/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.2727 - loss: 6.5668\n",
            "Epoch 42/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.2727 - loss: 5.8211\n",
            "Epoch 43/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - categorical_accuracy: 0.2727 - loss: 4.7065\n",
            "Epoch 44/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.5000 - loss: 3.3373\n",
            "Epoch 45/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - categorical_accuracy: 0.3636 - loss: 2.9173\n",
            "Epoch 46/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.1818 - loss: 4.9685\n",
            "Epoch 47/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3182 - loss: 5.8180\n",
            "Epoch 48/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - categorical_accuracy: 0.5000 - loss: 2.4088\n",
            "Epoch 49/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.5000 - loss: 1.9470\n",
            "Epoch 50/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.4091 - loss: 1.7846\n",
            "Epoch 51/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2273 - loss: 2.3833\n",
            "Epoch 52/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.3636 - loss: 3.2878\n",
            "Epoch 53/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 3.0134\n",
            "Epoch 54/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.4545 - loss: 3.1138\n",
            "Epoch 55/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.4091 - loss: 1.7210\n",
            "Epoch 56/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.4091 - loss: 2.3477\n",
            "Epoch 57/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2727 - loss: 1.9941\n",
            "Epoch 58/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3182 - loss: 6.0119\n",
            "Epoch 59/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.2727 - loss: 3.3481\n",
            "Epoch 60/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.3182 - loss: 2.6859\n",
            "Epoch 61/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3636 - loss: 2.8088\n",
            "Epoch 62/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.3636 - loss: 1.8495\n",
            "Epoch 63/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.5000 - loss: 2.3145\n",
            "Epoch 64/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - categorical_accuracy: 0.2727 - loss: 3.5224\n",
            "Epoch 65/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.2273 - loss: 2.6169\n",
            "Epoch 66/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.4091 - loss: 2.1937\n",
            "Epoch 67/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.3636 - loss: 1.8176\n",
            "Epoch 68/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3636 - loss: 2.0256\n",
            "Epoch 69/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3182 - loss: 4.8891\n",
            "Epoch 70/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3182 - loss: 3.1347\n",
            "Epoch 71/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.2273 - loss: 2.5143\n",
            "Epoch 72/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.2273 - loss: 2.3017\n",
            "Epoch 73/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.1818 - loss: 1.8371\n",
            "Epoch 74/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.5000 - loss: 1.9331\n",
            "Epoch 75/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.2273 - loss: 2.1623\n",
            "Epoch 76/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.2273 - loss: 2.2924\n",
            "Epoch 77/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - categorical_accuracy: 0.4545 - loss: 1.1459\n",
            "Epoch 78/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.5000 - loss: 1.3558\n",
            "Epoch 79/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.4091 - loss: 1.9844\n",
            "Epoch 80/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.1364 - loss: 2.0569\n",
            "Epoch 81/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.2727 - loss: 2.1518\n",
            "Epoch 82/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.2273 - loss: 1.8213\n",
            "Epoch 83/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.4091 - loss: 1.1145\n",
            "Epoch 84/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3182 - loss: 1.3076\n",
            "Epoch 85/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.2727 - loss: 1.7997\n",
            "Epoch 86/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - categorical_accuracy: 0.4545 - loss: 2.2123\n",
            "Epoch 87/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - categorical_accuracy: 0.1364 - loss: 4.3073\n",
            "Epoch 88/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.4091 - loss: 2.0789\n",
            "Epoch 89/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3636 - loss: 1.7508\n",
            "Epoch 90/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.9254\n",
            "Epoch 91/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.4545 - loss: 1.5736\n",
            "Epoch 92/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.5455 - loss: 2.3848\n",
            "Epoch 93/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - categorical_accuracy: 0.2727 - loss: 3.7429\n",
            "Epoch 94/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.2727 - loss: 2.2982\n",
            "Epoch 95/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - categorical_accuracy: 0.3182 - loss: 8.1001\n",
            "Epoch 96/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.0909 - loss: 2.6095\n",
            "Epoch 97/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.2273 - loss: 2.5395\n",
            "Epoch 98/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - categorical_accuracy: 0.2727 - loss: 2.0949\n",
            "Epoch 99/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3182 - loss: 1.9296\n",
            "Epoch 100/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.2727 - loss: 1.9075\n",
            "Epoch 101/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3636 - loss: 1.3184\n",
            "Epoch 102/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.4091 - loss: 1.2216\n",
            "Epoch 103/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3182 - loss: 3.0403\n",
            "Epoch 104/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.3182 - loss: 1.8421\n",
            "Epoch 105/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3636 - loss: 1.6392\n",
            "Epoch 106/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.7436\n",
            "Epoch 107/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3182 - loss: 1.1469\n",
            "Epoch 108/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.4091 - loss: 1.3496\n",
            "Epoch 109/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3182 - loss: 1.5428\n",
            "Epoch 110/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - categorical_accuracy: 0.3182 - loss: 1.3802\n",
            "Epoch 111/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - categorical_accuracy: 0.3636 - loss: 1.1945\n",
            "Epoch 112/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3636 - loss: 1.3333\n",
            "Epoch 113/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3636 - loss: 1.1202\n",
            "Epoch 114/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - categorical_accuracy: 0.3182 - loss: 1.1961\n",
            "Epoch 115/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3182 - loss: 1.2390\n",
            "Epoch 116/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3636 - loss: 1.1101\n",
            "Epoch 117/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.1341\n",
            "Epoch 118/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3636 - loss: 1.1851\n",
            "Epoch 119/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - categorical_accuracy: 0.3182 - loss: 1.1349\n",
            "Epoch 120/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.1262\n",
            "Epoch 121/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - categorical_accuracy: 0.4091 - loss: 1.1449\n",
            "Epoch 122/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - categorical_accuracy: 0.3182 - loss: 1.1182\n",
            "Epoch 123/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.4091 - loss: 1.0962\n",
            "Epoch 124/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.3636 - loss: 1.1357\n",
            "Epoch 125/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.1219\n",
            "Epoch 126/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.4091 - loss: 1.0910\n",
            "Epoch 127/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.3636 - loss: 1.1064\n",
            "Epoch 128/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - categorical_accuracy: 0.4091 - loss: 1.1049\n",
            "Epoch 129/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - categorical_accuracy: 0.4091 - loss: 1.0913\n",
            "Epoch 130/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.2273 - loss: 1.0994\n",
            "Epoch 131/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3636 - loss: 1.1025\n",
            "Epoch 132/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.2273 - loss: 1.0835\n",
            "Epoch 133/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.4091 - loss: 1.0817\n",
            "Epoch 134/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.3636 - loss: 1.0921\n",
            "Epoch 135/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.4545 - loss: 1.0834\n",
            "Epoch 136/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.3636 - loss: 1.0784\n",
            "Epoch 137/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.3636 - loss: 1.0840\n",
            "Epoch 138/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - categorical_accuracy: 0.3636 - loss: 1.0771\n",
            "Epoch 139/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.3636 - loss: 1.0737\n",
            "Epoch 140/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.5000 - loss: 1.0802\n",
            "Epoch 141/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.5000 - loss: 1.0780\n",
            "Epoch 142/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - categorical_accuracy: 0.3182 - loss: 1.0714\n",
            "Epoch 143/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - categorical_accuracy: 0.3636 - loss: 1.0731\n",
            "Epoch 144/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.3636 - loss: 1.0727\n",
            "Epoch 145/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - categorical_accuracy: 0.4091 - loss: 1.0681\n",
            "Epoch 146/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.5000 - loss: 1.0695\n",
            "Epoch 147/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.4545 - loss: 1.0690\n",
            "Epoch 148/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.4545 - loss: 1.0643\n",
            "Epoch 149/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.4545 - loss: 1.0638\n",
            "Epoch 150/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.4091 - loss: 1.0634\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b53cae9fca0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=150, callbacks=[tb_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxuuZJ2e-NKS",
        "outputId": "59e0dd95-f305-4749-9c5c-7707d577536c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        }
      ],
      "source": [
        "res = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j62Ydpa9-Qq9",
        "outputId": "9d2709b2-f3cf-4794-8492-b30d330b8db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNEn5qms-W_p"
      },
      "outputs": [],
      "source": [
        "model.save('action.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgUYjZye-p6K"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlWm4YMy-uL-"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUFIQUaN-xKR"
      },
      "outputs": [],
      "source": [
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdY_KhpC-0MB"
      },
      "outputs": [],
      "source": [
        "multilabel_confusion_matrix(ytrue, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYFcrNl0-3VA"
      },
      "outputs": [],
      "source": [
        "accuracy_score(ytrue, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmGmNu6lb7NG"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "rolXPEayb8HL",
        "outputId": "f8fc7df7-938c-46d7-ad64-f98f299ec764"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/MP_Data",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0dfff65507d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/MP_Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/MP_Data"
          ]
        }
      ],
      "source": [
        "files.download('/content/MP_Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2YTQ-_cCfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcTwAXOKiDgA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jar9L70AM3t7"
      },
      "source": [
        "try with lstm and cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EFOYCH9s8A_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg_8i4RvM52H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Parameters\n",
        "FRAME_SIZE = (64, 64)      # Resize frames to 64x64\n",
        "MAX_FRAMES = 30            # Max number of frames per video\n",
        "DATA_DIR = \"/content/WLPSL/Videos\"  # Update with your dataset path\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Loop through dataset directories\n",
        "for category in os.listdir(DATA_DIR):\n",
        "    category_path = os.path.join(DATA_DIR, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    for video_file in os.listdir(category_path):\n",
        "        video_path = os.path.join(category_path, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, FRAME_SIZE)\n",
        "            frame = frame / 255.0  # Normalize\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Pad or truncate frames to MAX_FRAMES\n",
        "        frames = pad_sequences([frames], maxlen=MAX_FRAMES, padding='post', dtype='float32')[0]\n",
        "\n",
        "        data.append(frames)\n",
        "        labels.append(category)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Save the preprocessed data\n",
        "with open(\"hand_sign_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((data, labels), f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4y9_bnINV-H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "with open(\"hand_sign_data.pkl\", \"rb\") as f:\n",
        "    data, labels = pickle.load(f)\n",
        "\n",
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq3ITgJ1NzP8",
        "outputId": "1093fa40-2c71-4acf-e78a-f5b1eef33ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, TimeDistributed, LSTM, Dense, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Feature extraction with CNN\n",
        "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(MAX_FRAMES, *FRAME_SIZE, 3)))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# LSTM for temporal processing\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-07ncDUtqwn"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcDGpNBHtwu2",
        "outputId": "d180970b-64e4-4188-dafd-180744c3921e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 398ms/step - accuracy: 0.0264 - loss: 3.6792 - val_accuracy: 0.0000e+00 - val_loss: 3.5702\n",
            "Epoch 2/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - accuracy: 0.0394 - loss: 3.4450 - val_accuracy: 0.0000e+00 - val_loss: 3.5011\n",
            "Epoch 3/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.0470 - loss: 3.4336 - val_accuracy: 0.0400 - val_loss: 3.4699\n",
            "Epoch 4/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - accuracy: 0.0458 - loss: 3.4362 - val_accuracy: 0.0000e+00 - val_loss: 3.4665\n",
            "Epoch 5/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - accuracy: 0.0646 - loss: 3.4282 - val_accuracy: 0.0000e+00 - val_loss: 3.4819\n",
            "Epoch 6/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.0498 - loss: 3.4284 - val_accuracy: 0.0000e+00 - val_loss: 3.4833\n",
            "Epoch 7/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - accuracy: 0.0655 - loss: 3.4384 - val_accuracy: 0.0000e+00 - val_loss: 3.4691\n",
            "Epoch 8/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.0912 - loss: 3.4066 - val_accuracy: 0.0400 - val_loss: 3.4820\n",
            "Epoch 9/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 0.0569 - loss: 3.4173 - val_accuracy: 0.0400 - val_loss: 3.4790\n",
            "Epoch 10/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - accuracy: 0.0500 - loss: 3.4122 - val_accuracy: 0.0000e+00 - val_loss: 3.5003\n",
            "Epoch 11/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.0706 - loss: 3.3831 - val_accuracy: 0.0000e+00 - val_loss: 3.4886\n",
            "Epoch 12/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - accuracy: 0.0430 - loss: 3.3660 - val_accuracy: 0.0000e+00 - val_loss: 3.5811\n",
            "Epoch 13/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.0666 - loss: 3.3754 - val_accuracy: 0.0400 - val_loss: 3.5970\n",
            "Epoch 14/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.0742 - loss: 3.3629 - val_accuracy: 0.0000e+00 - val_loss: 3.4922\n",
            "Epoch 15/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.0877 - loss: 3.3544 - val_accuracy: 0.0000e+00 - val_loss: 3.5484\n",
            "Epoch 16/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.0927 - loss: 3.2126 - val_accuracy: 0.0000e+00 - val_loss: 3.5428\n",
            "Epoch 17/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 0.1484 - loss: 2.9425 - val_accuracy: 0.0000e+00 - val_loss: 3.5438\n",
            "Epoch 18/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.1552 - loss: 2.9164 - val_accuracy: 0.0000e+00 - val_loss: 3.5899\n",
            "Epoch 19/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - accuracy: 0.1961 - loss: 2.8110 - val_accuracy: 0.0000e+00 - val_loss: 3.5363\n",
            "Epoch 20/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.2444 - loss: 2.5680 - val_accuracy: 0.0000e+00 - val_loss: 3.6350\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOVBsCdQt0S-",
        "outputId": "6df55ead-93f0-418f-81fe-5bd9e12195a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.0000e+00 - loss: 3.4861\n",
            "Test Accuracy: 0.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K7UNR4LzhB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eda172d-b256-4dff-9fbd-04e373060de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8e2ea42915a5>:6: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*FRAME_SIZE, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Dropout, Dense\n",
        "\n",
        "# Load MobileNetV2 for feature extraction\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*FRAME_SIZE, 3))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# TimeDistributed wrapper for applying the CNN to each frame\n",
        "model.add(TimeDistributed(base_model, input_shape=(MAX_FRAMES, *FRAME_SIZE, 3)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# LSTM layer for temporal sequence processing\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense output layer\n",
        "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anCF-Ei92Eso",
        "outputId": "49645ad5-0ff4-4dff-d212-660a3d277f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.1893 - loss: 2.9795 - val_accuracy: 0.0400 - val_loss: 3.2494 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.0531 - loss: 3.1488 - val_accuracy: 0.0800 - val_loss: 3.2293 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1510 - loss: 2.9563 - val_accuracy: 0.0400 - val_loss: 3.5467 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.1148 - loss: 3.0845 - val_accuracy: 0.0000e+00 - val_loss: 3.3890 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.1374 - loss: 3.0000 - val_accuracy: 0.0000e+00 - val_loss: 3.3543 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1146 - loss: 3.1005 - val_accuracy: 0.0400 - val_loss: 3.2993 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1046 - loss: 2.9959 - val_accuracy: 0.0400 - val_loss: 3.3872 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=16, class_weight=class_weights_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNr_AwHX2OR4",
        "outputId": "1a6e88a8-7d19-4fb2-ca16-1e648be71faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.0988 - loss: 2.9684 - val_accuracy: 0.0400 - val_loss: 3.3198\n",
            "Epoch 2/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.1047 - loss: 2.9456 - val_accuracy: 0.0000e+00 - val_loss: 3.3492\n",
            "Epoch 3/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1415 - loss: 2.8747 - val_accuracy: 0.0400 - val_loss: 3.3488\n",
            "Epoch 4/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1308 - loss: 2.8962 - val_accuracy: 0.0000e+00 - val_loss: 3.4701\n",
            "Epoch 5/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.1587 - loss: 2.9391 - val_accuracy: 0.0400 - val_loss: 3.4955\n",
            "Epoch 6/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1340 - loss: 2.8463 - val_accuracy: 0.0400 - val_loss: 3.4452\n",
            "Epoch 7/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.1669 - loss: 2.7996 - val_accuracy: 0.0400 - val_loss: 3.5642\n",
            "Epoch 8/20\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.1896 - loss: 2.7233 - val_accuracy: 0.0400 - val_loss: 3.6818\n",
            "Epoch 9/20\n",
            "\u001b[1m 4/13\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 931ms/step - accuracy: 0.1289 - loss: 2.7465"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o1dwWqZa5HWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VaPZoYGnw45y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing videos\n",
        "video_folder = '/content/WLPSL/Videos1'  # Update with the path to your videos\n",
        "# Directory to save extracted frames\n",
        "output_folder = 'MP_Data'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "# Number of frames to extract per video\n",
        "frames_per_sequence = 30\n",
        "\n",
        "# Function to extract exactly 30 frames uniformly\n",
        "def extract_frames_from_video(video_path, output_folder, gesture_folder, video_index):\n",
        "  #with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate frame indices to sample\n",
        "    frame_indices = np.linspace(0, total_frames - 1, frames_per_sequence, dtype=int)\n",
        "\n",
        "    extracted_count = 0\n",
        "    output_subfolder = os.path.join(output_folder, gesture_folder, str(video_index))\n",
        "    os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "    frame_count = 0\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        #image, results = mediapipe_detection(frame, holistic)\n",
        "        #draw_styled_landmarks(image, results)\n",
        "\n",
        "\n",
        "        if frame_count in frame_indices:\n",
        "            # Preprocess frame (example: using Mediapipe or other processing)\n",
        "            #keypoints = extract_keypoints(results)  # Replace with your desired preprocessing logic\n",
        "            frame_filename = os.path.join(output_subfolder, f\"{extracted_count + 1}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            extracted_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "# Loop through all videos in the folder\n",
        "for gesture_folder in os.listdir(video_folder):\n",
        "    gesture_path = os.path.join(video_folder, gesture_folder)\n",
        "\n",
        "    if os.path.isdir(gesture_path):  # Check if it's a folder for gestures\n",
        "        video_index = 1  # Start numbering videos from 1\n",
        "        for filename in os.listdir(gesture_path):\n",
        "            if filename.endswith(\".mp4\") or filename.endswith(\".avi\"):  # Adjust for your video file type\n",
        "                video_path = os.path.join(gesture_path, filename)\n",
        "                extract_frames_from_video(video_path, output_folder, gesture_folder, video_index)\n",
        "                print(f\"Frames extracted for {filename} in gesture folder '{gesture_folder}'\")\n",
        "                video_index += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mq1i4ZXw4qA",
        "outputId": "675ee39f-4c01-41ca-94dd-aed4229c27b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames extracted for 6.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 7.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 2.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 8.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 1.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 4.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 3.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 5.mp4 in gesture folder 'cheap'\n",
            "Frames extracted for 6.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 7.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 2.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 8.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 1.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 4.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 3.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 5.mp4 in gesture folder 'alert'\n",
            "Frames extracted for 6.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 7.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 2.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 8.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 1.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 4.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 3.mp4 in gesture folder 'careful'\n",
            "Frames extracted for 5.mp4 in gesture folder 'careful'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/MP_Data1\")"
      ],
      "metadata": {
        "id": "1UM02nNGyWin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Folder path to compress\n",
        "folder_path = '/content/MP_Data/alert/8'\n",
        "# Output zip file\n",
        "zip_file_path = '/content/alert_8.zip'\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5jd9h83Iy0T3",
        "outputId": "cf2b4d2a-a499-4e15-d8bd-a0c14dd934a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/alert_8.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jOuFvMg-5L9S",
        "outputId": "373307bf-2985-4518-d571-359402bc0971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a7740022-fdf2-420d-b234-171dfebfed5b\", \"alert_8.zip\", 4329818)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d saadbutt321/pakistan-sign-language-dataset"
      ],
      "metadata": {
        "id": "hPQO2WKM5SRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36120c6a-5157-4c7a-9c67-ed64f8a83386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/saadbutt321/pakistan-sign-language-dataset\n",
            "License(s): GPL-2.0\n",
            "Downloading pakistan-sign-language-dataset.zip to /content\n",
            "  0% 0.00/4.09M [00:00<?, ?B/s]\n",
            "100% 4.09M/4.09M [00:00<00:00, 64.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "data='/content/pakistan-sign-language-dataset.zip'\n",
        "with ZipFile(data,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Data set is extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLE-aE5rBTaq",
        "outputId": "3abd420f-1359-4c3a-8cd9-96019a3ad83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ICNXNfvEfcf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}